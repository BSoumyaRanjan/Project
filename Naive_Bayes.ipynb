{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_Bayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjDnJZ8E7f_U"
      },
      "source": [
        "Importing useful Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kl9uGOe7K1H"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEAWbu7-7S0y"
      },
      "source": [
        "path=\"https://raw.githubusercontent.com/Ashutoshrx/Natural-Language-Processing/main/data/spam.csv\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbdX9lid7WjX"
      },
      "source": [
        "df = pd.read_csv(path,encoding='latin-1')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bMSiRXt7dcu",
        "outputId": "041302e9-eb39-4c00-fba2-a4e68ab845b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1  ... Unnamed: 4\n",
              "0   ham  ...        NaN\n",
              "1   ham  ...        NaN\n",
              "2  spam  ...        NaN\n",
              "3   ham  ...        NaN\n",
              "4   ham  ...        NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW7-nkEM7iiP",
        "outputId": "ddf8c706-1eca-4ddd-c98e-50a1b537aa23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1vGu3H17qX3"
      },
      "source": [
        "Checking for duplicates and removing them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9Fa91hb7o6n"
      },
      "source": [
        "df.drop_duplicates(inplace = True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcwWVUE67uv1"
      },
      "source": [
        "Show the new shape (number of rows & columns)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpeDfh_67sC3",
        "outputId": "fb8e69e7-6242-4782-d5a8-7caba51f854b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5169, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2uSKz6k7zBj"
      },
      "source": [
        "Show the number of missing (NAN, NaN, na) data for each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nVIjXXw7uY-",
        "outputId": "06bdfcff-5d60-4a1d-df43-4fd973a3126c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "\n",
        "df.isnull().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "v1               0\n",
              "v2               0\n",
              "Unnamed: 2    5126\n",
              "Unnamed: 3    5159\n",
              "Unnamed: 4    5164\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHP71ecg74x9"
      },
      "source": [
        "Need to download stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkRDGDmS70fo",
        "outputId": "396cb0f4-ba4a-4aed-a9fb-6932c36750e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW1nA8DO77fq"
      },
      "source": [
        "**\n",
        "1.Tokenization (a list of tokens), will be used as the analyzer\n",
        "\n",
        "2.Punctuations are [!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\n",
        "\n",
        "3.Stop words in natural language processing, are useless words (data). \n",
        "**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n84T_hEc75UG"
      },
      "source": [
        "\n",
        "def process_text(text):\n",
        "    \n",
        "    #1 Remove Punctuationa\n",
        "    nopunc = [char for char in text if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "    \n",
        "    #2 Remove Stop Words\n",
        "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
        "    \n",
        "    #3 Return a list of clean words\n",
        "    return clean_words"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rWB4b2I7_1v",
        "outputId": "f8667842-2f02-4494-9aaf-ecba6f41329b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#Show the Tokenization (a list of tokens )\n",
        "df['v2'].head().apply(process_text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
              "1                       [Ok, lar, Joking, wif, u, oni]\n",
              "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
              "3        [U, dun, say, early, hor, U, c, already, say]\n",
              "4    [Nah, dont, think, goes, usf, lives, around, t...\n",
              "Name: v2, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krgS77Pn8B9_"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "messages_bow = CountVectorizer(analyzer=process_text).fit_transform(df['v2'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fONJrc-I8RGf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(messages_bow, df['v1'], test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45jpQ5T08eMm",
        "outputId": "1f0e3135-4c63-4c28-833f-334172b5a573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape,messages_bow.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4135, 11304), (1034, 11304), (4135,), (1034,), (5169, 11304))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXXQNecX8jUe",
        "outputId": "5a30689c-6fc3-47f4-bf1a-9cfe2d7e4b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhDtqZgi8zFY",
        "outputId": "2b75c77f-07e0-458b-ae42-72288285fdac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Print the predictions\n",
        "print(classifier.predict(X_train))\n",
        "#Print the actual values\n",
        "print(y_train.values)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n",
            "['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev8yyCJO82of",
        "outputId": "4b381564-e289-43f0-8109-4918bb66290d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "#Evaluate the model on the training data set\n",
        "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
        "pred = classifier.predict(X_train)\n",
        "print(classification_report(y_train ,pred ))\n",
        "print('Confusion Matrix: \\n',confusion_matrix(y_train,pred))\n",
        "print()\n",
        "print('Accuracy for training data: ', accuracy_score(y_train,pred))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      1.00      1.00      3631\n",
            "        spam       0.98      0.98      0.98       504\n",
            "\n",
            "    accuracy                           1.00      4135\n",
            "   macro avg       0.99      0.99      0.99      4135\n",
            "weighted avg       1.00      1.00      1.00      4135\n",
            "\n",
            "Confusion Matrix: \n",
            " [[3623    8]\n",
            " [  11  493]]\n",
            "\n",
            "Accuracy for training data:  0.9954050785973397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxccO4dV86JX",
        "outputId": "a7a55698-5254-45e7-a92d-1b1d95e8b021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Print the predictions\n",
        "print('Predicted value: ',classifier.predict(X_test))\n",
        "#Print Actual Label\n",
        "print('Actual value: ',y_test.values)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted value:  ['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n",
            "Actual value:  ['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x4iEwm34Blh"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs9I6p5d89jO",
        "outputId": "b5dc53d5-20ad-4b44-981c-92b961c9ed2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "#Evaluate the model on the test data set\n",
        "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
        "pred = classifier.predict(X_test)\n",
        "print(classification_report(y_test ,pred ))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test,pred))\n",
        "print()\n",
        "print('Naive Bayes accuracy score in %: ', accuracy_score(y_test,pred)*100)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.96      0.97       885\n",
            "        spam       0.80      0.93      0.86       149\n",
            "\n",
            "    accuracy                           0.96      1034\n",
            "   macro avg       0.89      0.94      0.92      1034\n",
            "weighted avg       0.96      0.96      0.96      1034\n",
            "\n",
            "Confusion Matrix: \n",
            " [[850  35]\n",
            " [ 11 138]]\n",
            "\n",
            "Naive Bayes accuracy score in %:  95.55125725338492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XSCa79WwGla"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}